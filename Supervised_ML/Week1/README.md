# Linear Regression with Gradient Descent

## Overview

This week 1 provides a practical implementation of linear regression using gradient descent. The project focuses on fitting a linear model to predict housing prices based on house size, optimizing model parameters, and visualizing the learning process.

## What I Learn

1. **Linear Regression Basics:**
   - Understand how linear regression models the relationship between features (e.g., house size) and targets (e.g., house price).

2. **Cost Function/ Loss Function:**
   - Learn to compute the cost function to measure the model's performance and how well it fits the training data.

3. **Gradient Descent:**
   - Implement gradient descent to iteratively adjust model parameters \( w \) (weight) and \( b \) (bias) to minimize the cost function.

4. **Parameter Optimization:**
   - Use gradients to update parameters and track the convergence of the model through cost versus iteration plots.

5. **Prediction:**
   - Make predictions for new data points using the trained model.

## Features

- **Cost Function Calculation:** Computes the cost of the model's predictions compared to actual values.
- **Gradient Computation:** Calculates gradients to guide parameter updates.
- **Gradient Descent Algorithm:** Optimizes parameters through iterative updates.
- **Visualization:** Plots cost over iterations, parameter paths, and model predictions.

## Getting Started

1. Clone the repository and navigate to the project directory.
2. Install required dependencies.
3. Run the provided scripts to see the implementation in action, from fitting the model to making predictions.

## Conclusion

This project demonstrates the core concepts of linear regression and gradient descent, offering hands-on experience with model fitting, optimization, and evaluation. It provides a foundation for understanding more complex machine learning techniques.
